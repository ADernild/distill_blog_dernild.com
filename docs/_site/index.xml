<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>Alexander Dernild</title>
    <link>https://dernild.com</link>
    <atom:link href="https://dernild.com/index.xml" rel="self" type="application/rss+xml"/>
    <description>Personal website/blog by Alexander Dernild showcasing Data Science projects.
</description>
    <image>
      <title>Alexander Dernild</title>
      <url>https://dernild.com/src/images/circle-cropped-profile-pic.png</url>
      <link>https://dernild.com</link>
    </image>
    <generator>Distill</generator>
    <lastBuildDate>Wed, 02 Dec 2020 00:00:00 +0000</lastBuildDate>
    <item>
      <title>Collecting and cleaning Tweets for a NLP project</title>
      <dc:creator>Alexander Dernild</dc:creator>
      <link>https://dernild.com/posts/2020-12-02-collecting-and-cleaning-tweets-for-a-nlp-project</link>
      <description>As a part of a Natural Language Processing project, focused on the US presidential debates and election 2020, I collected a total amount of 325.314 unique tweets. In this post, I will explain how I managed to do this, utilizing Twitter's API and R Studio.</description>
      <category>Twitter Data</category>
      <category>NLP</category>
      <category>pres_debate</category>
      <guid>https://dernild.com/posts/2020-12-02-collecting-and-cleaning-tweets-for-a-nlp-project</guid>
      <pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>
